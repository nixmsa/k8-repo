[root@k8 kube-mongodb]# kubectl describe rc mongo
Name:         mongo
Namespace:    default
Selector:     app=mongo
Labels:       app=mongo
Annotations:  <none>
Replicas:     2 current / 2 desired
Pods Status:  2 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  app=mongo
  Containers:
   mongo:
    Image:        mongo
    Port:         27017/TCP
    Host Port:    0/TCP
    Environment:  <none>
    Mounts:
      /mongo/data/db from mongo-storage (rw)
  Volumes:
   mongo-storage:
    Type:    EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
Events:
  Type    Reason            Age    From                    Message
  ----    ------            ----   ----                    -------
  Normal  SuccessfulCreate  2m49s  replication-controller  Created pod: mongo-dcnwg
  Normal  SuccessfulCreate  2m49s  replication-controller  Created pod: mongo-kdtgl
[root@k8 kube-mongodb]#

#####
[root@k8 kube-oracle]# kubectl get pod -o wide;
NAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE
mongo-dcnwg   1/1     Running   0          4m30s   10.47.0.1   k2.bc.ca   <none>
mongo-kdtgl   1/1     Running   0          4m30s   10.47.0.2   k2.bc.ca   <none>
oradb-57w46   1/1     Running   0          3h18m   10.47.0.4   k2.bc.ca   <none>
oradb-mjzq8   1/1     Unknown   0          9h      10.44.0.2   k1.bc.ca   <none>
oradb-ts8lc   1/1     Running   0          3h18m   10.47.0.5   k2.bc.ca   <none>
oradb-zrssr   1/1     Running   0          3h17m   10.47.0.6   k2.bc.ca   <none>
[root@k8 kube-oracle]#

[root@k8 kube-oracle]# kubectl get rc -o wide;
NAME    DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES                 SELECTOR
mongo   2         2         2       5m12s   mongo        mongo                  app=mongo
oradb   3         3         3       9h      oradb        sath89/oracle-xe-11g   app=oradb
[root@k8 kube-oracle]# kubectl get svc -o wide;
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE     SELECTOR
kubernetes   ClusterIP      10.96.0.1       <none>        443/TCP           5d20h   <none>
mongo        LoadBalancer   10.105.25.141   <pending>     27017:31946/TCP   7h16m   app=mongo
oradb        ClusterIP      10.105.189.3    <none>        1521/TCP          10h     app=oradb
[root@k8 kube-oracle]#

[root@k8 kube-oracle]# kubectl describe svc mongo
Name:                     mongo
Namespace:                default
Labels:                   app=mongo
Annotations:              <none>
Selector:                 app=mongo
Type:                     LoadBalancer
IP:                       10.105.25.141
Port:                     mongo  27017/TCP
TargetPort:               27017/TCP
NodePort:                 mongo  31946/TCP
Endpoints:                10.47.0.1:27017,10.47.0.2:27017
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
[root@k8 kube-oracle]#


[root@k8 kube-oracle]# kubectl get pod -o wide;
NAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE
mongo-dcnwg   1/1     Running   0          6m18s   10.47.0.1   k2.bc.ca   <none>
mongo-kdtgl   1/1     Running   0          6m18s   10.47.0.2   k2.bc.ca   <none>
oradb-57w46   1/1     Running   0          3h20m   10.47.0.4   k2.bc.ca   <none>
oradb-mjzq8   1/1     Unknown   0          9h      10.44.0.2   k1.bc.ca   <none>
oradb-ts8lc   1/1     Running   0          3h20m   10.47.0.5   k2.bc.ca   <none>
oradb-zrssr   1/1     Running   0          3h19m   10.47.0.6   k2.bc.ca   <none>
[root@k8 kube-oracle]# kubectl describe pod mongo-kdtgl
Name:               mongo-kdtgl
Namespace:          default
Priority:           0
PriorityClassName:  <none>
Node:               k2.bc.ca/192.168.1.102
Start Time:         Fri, 02 Nov 2018 21:54:17 -0400
Labels:             app=mongo
Annotations:        <none>
Status:             Running
IP:                 10.47.0.2
Controlled By:      ReplicationController/mongo
Containers:
  mongo:
    Container ID:   docker://e5e5cd50b5a8ff75f743c235f9d47f21974be3455bc21b2806f98834332f9b50
    Image:          mongo
    Image ID:       docker-pullable://docker.io/mongo@sha256:c4e8225e68348b18283cf5c523f99122426fe1e15d883104e24c61bedb4b2ca7
    Port:           27017/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Fri, 02 Nov 2018 21:54:23 -0400
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /mongo/data/db from mongo-storage (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-v46ft (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  mongo-storage:
    Type:    EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
  default-token-v46ft:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-v46ft
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  6m30s  default-scheduler  Successfully assigned default/mongo-kdtgl to k2.bc.ca
  Normal  Pulling    6m28s  kubelet, k2.bc.ca  pulling image "mongo"
  Normal  Pulled     6m24s  kubelet, k2.bc.ca  Successfully pulled image "mongo"
  Normal  Created    6m24s  kubelet, k2.bc.ca  Created container
  Normal  Started    6m24s  kubelet, k2.bc.ca  Started container
[root@k8 kube-oracle]#


[root@k8 kube-oracle]# kubectl logs mongo-dcnwg
2018-11-03T01:54:23.312+0000 I CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] MongoDB starting : pid=1 port=27017 dbpath=/data/db 64-bit host=mongo-dcnwg
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] db version v4.0.3
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] git version: 7ea530946fa7880364d88c8d8b6026bbc9ffa48c
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.2g  1 Mar 2016
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] allocator: tcmalloc
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] modules: none
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] build environment:
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten]     distmod: ubuntu1604
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten]     distarch: x86_64
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten]     target_arch: x86_64
2018-11-03T01:54:23.359+0000 I CONTROL  [initandlisten] options: { net: { bindIpAll: true } }
2018-11-03T01:54:23.360+0000 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=407M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),
2018-11-03T01:54:24.304+0000 I STORAGE  [initandlisten] WiredTiger message [1541210064:304853][1:0x7fc826170a00], txn-recover: Set global recovery timestamp: 0
2018-11-03T01:54:24.338+0000 I RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2018-11-03T01:54:24.343+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.343+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2018-11-03T01:54:24.343+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2018-11-03T01:54:24.343+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2018-11-03T01:54:24.344+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.344+0000 I STORAGE  [initandlisten] createCollection: admin.system.version with provided UUID: 3f4e512d-108d-4fed-95f2-6edb58d52399
2018-11-03T01:54:24.383+0000 I COMMAND  [initandlisten] setting featureCompatibilityVersion to 4.0
2018-11-03T01:54:24.389+0000 I STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 5d2eff46-add0-4f52-97a5-474303009e49
2018-11-03T01:54:24.406+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'
2018-11-03T01:54:24.430+0000 I NETWORK  [initandlisten] waiting for connections on port 27017
2018-11-03T01:54:24.431+0000 I STORAGE  [LogicalSessionCacheRefresh] createCollection: config.system.sessions with generated UUID: d35ba765-7c3c-443a-ba86-8f265fac6fb8
2018-11-03T01:54:24.457+0000 I INDEX    [LogicalSessionCacheRefresh] build index on: config.system.sessions properties: { v: 2, key: { lastUse: 1 }, name: "lsidTTLIndex", ns: "config.system.sessions", expireAfterSeconds: 1800 }
2018-11-03T01:54:24.457+0000 I INDEX    [LogicalSessionCacheRefresh]     building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-11-03T01:54:24.458+0000 I INDEX    [LogicalSessionCacheRefresh] build index done.  scanned 0 total records. 0 secs
[root@k8 kube-oracle]#

###

[root@k2 ~]# docker ps -a | grep mongo
e5e5cd50b5a8        docker.io/mongo@sha256:c4e8225e68348b18283cf5c523f99122426fe1e15d883104e24c61bedb4b2ca7                  "docker-entrypoint..."   10 minutes ago      Up 10 minutes                                 k8s_mongo_mongo-kdtgl_default_5f45e5ae-df0b-11e8-bb7a-000c29786f82_0
c34f74d64314        docker.io/mongo@sha256:c4e8225e68348b18283cf5c523f99122426fe1e15d883104e24c61bedb4b2ca7                  "docker-entrypoint..."   10 minutes ago      Up 10 minutes                                 k8s_mongo_mongo-dcnwg_default_5f4464e3-df0b-11e8-bb7a-000c29786f82_0
dddf76c66f42        k8s.gcr.io/pause:3.1                                                                                     "/pause"                 10 minutes ago      Up 10 minutes                                 k8s_POD_mongo-kdtgl_default_5f45e5ae-df0b-11e8-bb7a-000c29786f82_0
fc42d5e7b11b        k8s.gcr.io/pause:3.1                                                                                     "/pause"                 10 minutes ago      Up 10 minutes                                 k8s_POD_mongo-dcnwg_default_5f4464e3-df0b-11e8-bb7a-000c29786f82_0
[root@k2 ~]#


[root@k2 ~]# docker exec -it e5e5cd50b5a8 bash
root@mongo-kdtgl:/#

root@mongo-kdtgl:/# cd /mongo/data/db/
root@mongo-kdtgl:/mongo/data/db# ll
total 0
drwxrwxrwx 2 root root  6 Nov  3 01:54 ./
drwxr-xr-x 3 root root 16 Nov  3 01:54 ../
root@mongo-kdtgl:/mongo/data/db# ls -a
.  ..
root@mongo-kdtgl:/mongo/data/db#


####
access mongo 
#####
# Kubernetes-managed hosts file.
127.0.0.1       localhost
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
fe00::0 ip6-mcastprefix
fe00::1 ip6-allnodes
fe00::2 ip6-allrouters
10.47.0.2       mongo-kdtgl
root@mongo-kdtgl:/mongo/data/db# pwd
/mongo/data/db
root@mongo-kdtgl:/mongo/data/db# mongo
MongoDB shell version v4.0.3
connecting to: mongodb://127.0.0.1:27017
Implicit session: session { "id" : UUID("cc8c22be-9da2-4b66-b861-a6aaa989c472") }
MongoDB server version: 4.0.3
Welcome to the MongoDB shell.
For interactive help, type "help".
For more comprehensive documentation, see
        http://docs.mongodb.org/
Questions? Try the support group
        http://groups.google.com/group/mongodb-user
Server has startup warnings:
2018-11-03T01:54:24.872+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten]
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2018-11-03T01:54:24.873+0000 I CONTROL  [initandlisten]
---
Enable MongoDB's free cloud-based monitoring service, which will then receive and display
metrics about your deployment (disk utilization, CPU, operation statistics, etc).

The monitoring data will be available on a MongoDB website with a unique URL accessible to you
and anyone you share the URL with. MongoDB may use this information to make product
improvements and to suggest MongoDB products and deployment options to you.

To enable free monitoring, run the following command: db.enableFreeMonitoring()
To permanently disable this reminder, run the following command: db.disableFreeMonitoring()
---

>
> show dbs
admin   0.000GB
config  0.000GB
local   0.000GB
>

> show dbs
admin   0.000GB
config  0.000GB
local   0.000GB
>

> use mongodb
switched to db mongodb
> show dbs
admin   0.000GB
config  0.000GB
local   0.000GB
> db.createCollection("catalog")
{ "ok" : 1 }
> show dbs
admin    0.000GB
config   0.000GB
local    0.000GB
mongodb  0.000GB
> show collections
catalog
>

> db.createCollection("catalog_capped", {capped: true, autoIndexId: true, size: 64 * 1024, max: 1000} )
{
        "note" : "the autoIndexId option is deprecated and will be removed in a future release",
        "ok" : 1
}
>
}
> db.catalog.count()
0
>
> doc = {"catalogId" : "catalog1", "journal": 'Oracle Magazine', "publisher": 'Oracle Publishing', "edition": 'November December 2013', "title" : 'enginerring as a service', "author" : 'david a kelly'}
{
        "catalogId" : "catalog1",
        "journal" : "Oracle Magazine",
        "publisher" : "Oracle Publishing",
        "edition" : "November December 2013",
        "title" : "enginerring as a service",
        "author" : "david a kelly"
}
> doc = {"catalogId" : "catalog1", "journal": 'Oracle Magazine', "publisher": 'Oracle Publishing', "edition": 'November December 2013', "title" : 'enginerring as a service', "author" : 'david a kelly'}
{
        "catalogId" : "catalog1",
        "journal" : "Oracle Magazine",
        "publisher" : "Oracle Publishing",
        "edition" : "November December 2013",
        "title" : "enginerring as a service",
        "author" : "david a kelly"
}
>
[root@k8 ~]# kubectl scale rc mongo --replicas=4
replicationcontroller/mongo scaled
[root@k8 ~]# kubectl get rc
NAME    DESIRED   CURRENT   READY   AGE
mongo   4         4         2       151m
oradb   3         3         3       11h
[root@k8 ~]# kubectl get pod -o wide;
NAME          READY   STATUS              RESTARTS   AGE     IP          NODE       NOMINATED NODE
mongo-6cwbh   0/1     ContainerCreating   0          19s     <none>      k2.bc.ca   <none>
mongo-cstzs   1/1     Running             0          19s     10.47.0.7   k2.bc.ca   <none>
mongo-dcnwg   1/1     Running             0          151m    10.47.0.1   k2.bc.ca   <none>
mongo-kdtgl   1/1     Running             0          151m    10.47.0.2   k2.bc.ca   <none>
oradb-57w46   1/1     Running             0          5h46m   10.47.0.4   k2.bc.ca   <none>
oradb-mjzq8   1/1     Unknown             0          11h     10.44.0.2   k1.bc.ca   <none>
oradb-ts8lc   1/1     Running             0          5h46m   10.47.0.5   k2.bc.ca   <none>
oradb-zrssr   1/1     Running             0          5h44m   10.47.0.6   k2.bc.ca   <none>
[root@k8 ~]#


[root@k8 ~]# kubectl delete replicationcontroller mongo
replicationcontroller "mongo" deleted
[root@k8 ~]#

mongo-kdtgl   1/1   Terminating   0     154m   10.47.0.2   k2.bc.ca   <none>
mongo-6cwbh   1/1   Terminating   0     3m24s   10.47.0.3   k2.bc.ca   <none>
mongo-cstzs   1/1   Terminating   0     3m24s   10.47.0.7   k2.bc.ca   <none>
mongo-dcnwg   1/1   Terminating   0     154m   10.47.0.1   k2.bc.ca   <none>
mongo-6cwbh   0/1   Terminating   0     3m30s   10.47.0.3   k2.bc.ca   <none>
mongo-6cwbh   0/1   Terminating   0     3m31s   10.47.0.3   k2.bc.ca   <none>
mongo-kdtgl   0/1   Terminating   0     154m   10.47.0.2   k2.bc.ca   <none>
mongo-dcnwg   0/1   Terminating   0     154m   10.47.0.1   k2.bc.ca   <none>
mongo-dcnwg   0/1   Terminating   0     154m   10.47.0.1   k2.bc.ca   <none>
mongo-cstzs   0/1   Terminating   0     3m31s   <none>   k2.bc.ca   <none>
mongo-kdtgl   0/1   Terminating   0     155m   10.47.0.2   k2.bc.ca   <none>
mongo-kdtgl   0/1   Terminating   0     155m   10.47.0.2   k2.bc.ca   <none>
mongo-6cwbh   0/1   Terminating   0     3m36s   10.47.0.3   k2.bc.ca   <none>
mongo-6cwbh   0/1   Terminating   0     3m36s   10.47.0.3   k2.bc.ca   <none>
mongo-cstzs   0/1   Terminating   0     3m36s   <none>   k2.bc.ca   <none>
mongo-cstzs   0/1   Terminating   0     3m36s   <none>   k2.bc.ca   <none>
mongo-dcnwg   0/1   Terminating   0     155m   10.47.0.1   k2.bc.ca   <none>
mongo-dcnwg   0/1   Terminating   0     155m   10.47.0.1   k2.bc.ca   <none>

[root@k8 ~]# kubectl get pod -o wide;
NAME          READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE
oradb-57w46   1/1     Running   0          5h51m   10.47.0.4   k2.bc.ca   <none>
oradb-mjzq8   1/1     Unknown   0          11h     10.44.0.2   k1.bc.ca   <none>
oradb-ts8lc   1/1     Running   0          5h51m   10.47.0.5   k2.bc.ca   <none>
oradb-zrssr   1/1     Running   0          5h50m   10.47.0.6   k2.bc.ca   <none>
[root@k8 ~]# kubectl get rc
NAME    DESIRED   CURRENT   READY   AGE
oradb   3         3         3       11h
[root@k8 ~]#

[root@k8 ~]# kubectl get svc
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE
kubernetes   ClusterIP      10.96.0.1       <none>        443/TCP           5d23h
mongo        LoadBalancer   10.105.25.141   <pending>     27017:31946/TCP   9h
oradb        ClusterIP      10.105.189.3    <none>        1521/TCP          12h
[root@k8 ~]# kubectl delete svc mongo
service "mongo" deleted
[root@k8 ~]# kubectl get svc
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
kubernetes   ClusterIP   10.96.0.1      <none>        443/TCP    5d23h
oradb        ClusterIP   10.105.189.3   <none>        1521/TCP   12h
[root@k8 ~]#

####
[root@k8 kube-mongodb]# kubectl create -f mongo-hostport.yaml
replicationcontroller/mongo created
[root@k8 kube-mongodb]# kubectl get rc
NAME    DESIRED   CURRENT   READY   AGE
mongo   2         2         0       11s
oradb   3         3         3       12h
[root@k8 kube-mongodb]# kubectl get pod;
NAME          READY   STATUS    RESTARTS   AGE
mongo-9rsgc   0/1     Pending   0          26s
mongo-z69cp   1/1     Running   0          26s
oradb-57w46   1/1     Running   0          6h8m
oradb-mjzq8   1/1     Unknown   0          12h
oradb-ts8lc   1/1     Running   0          6h8m
oradb-zrssr   1/1     Running   0          6h7m
[root@k8 kube-mongodb]#

[root@k8 kube-mongodb]# kubectl scale rc mongo --replicas=4
replicationcontroller/mongo scaled
[root@k8 kube-mongodb]# kubectl get pod;
NAME          READY   STATUS    RESTARTS   AGE
mongo-542ss   0/1     Pending   0          7s
mongo-9rsgc   0/1     Pending   0          3m2s
mongo-hsdtl   0/1     Pending   0          7s
mongo-z69cp   1/1     Running   0          3m2s
oradb-57w46   1/1     Running   0          6h11m
oradb-mjzq8   1/1     Unknown   0          12h
oradb-ts8lc   1/1     Running   0          6h11m
oradb-zrssr   1/1     Running   0          6h10m
[root@k8 kube-mongodb]#
[root@k8 kube-mongodb]# kubectl delete pod mongo-z69cp
pod "mongo-z69cp" deleted
[root@k8 kube-mongodb]# kubectl get pod;
NAME          READY   STATUS              RESTARTS   AGE
mongo-542ss   0/1     Pending             0          2m44s
mongo-9rsgc   0/1     Pending             0          5m39s
mongo-hsdtl   0/1     Pending             0          2m44s
mongo-rmrdl   0/1     ContainerCreating   0          12s
oradb-57w46   1/1     Running             0          6h13m
oradb-mjzq8   1/1     Unknown             0          12h
oradb-ts8lc   1/1     Running             0          6h13m
oradb-zrssr   1/1     Running             0          6h12m
[root@k8 kube-mongodb]#

oradb-zrssr   1/1     Running             0          6h12m
[root@k8 kube-mongodb]# kubectl get pod;
NAME          READY   STATUS    RESTARTS   AGE
mongo-542ss   0/1     Pending   0          3m9s
mongo-9rsgc   0/1     Pending   0          6m4s
mongo-hsdtl   0/1     Pending   0          3m9s
mongo-rmrdl   1/1     Running   0          37s
oradb-57w46   1/1     Running   0          6h14m
oradb-mjzq8   1/1     Unknown   0          12h
oradb-ts8lc   1/1     Running   0          6h14m
oradb-zrssr   1/1     Running   0          6h13m
[root@k8 kube-m


[root@k8 kube-mongodb]# kubectl run mongo --image=mongo --replicas=2 --port=27017
kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.
deployment.apps/mongo created
[root@k8 kube-mongodb]# kubectl get rc
NAME    DESIRED   CURRENT   READY   AGE
mongo   4         4         1       11m
oradb   3         3         3       12h
[root@k8 kube-mongodb]# kubectl get pods;
NAME                     READY   STATUS    RESTARTS   AGE
mongo-542ss              0/1     Pending   0          8m40s
mongo-5465658856-rl7hk   1/1     Running   0          23s
mongo-5465658856-zq6zf   1/1     Running   0          23s
mongo-9rsgc              0/1     Pending   0          11m
mongo-hsdtl              0/1     Pending   0          8m40s
mongo-rmrdl              1/1     Running   0          6m8s
oradb-57w46              1/1     Running   0          6h19m
oradb-mjzq8              1/1     Unknown   0          12h
oradb-ts8lc              1/1     Running   0          6h19m
oradb-zrssr              1/1     Running   0          6h18m
[root@k8 kube-mongodb]#

[root@k8 kube-mongodb]# kubectl expose rc mongo --port=27017 --type=LoadBalancer
service/mongo exposed
[root@k8 kube-mongodb]# kubectl get rc
NAME    DESIRED   CURRENT   READY   AGE
mongo   4         4         1       15m
oradb   3         3         3       12h
[root@k8 kube-mongodb]#

[root@k8 kube-mongodb]# kubectl get svc
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE
kubernetes   ClusterIP      10.96.0.1       <none>        443/TCP           5d23h
mongo        LoadBalancer   10.105.33.248   <pending>     27017:30879/TCP   53s
oradb        ClusterIP      10.105.189.3    <none>        1521/TCP          13h
[root@k8 kube-mongodb]#





